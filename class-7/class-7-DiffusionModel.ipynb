{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nispoe/GWU-SEAS-8525/blob/main/class-7/class-7-DiffusionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_gvC5rx43Ws"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
        "\n",
        "import math\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    utils,\n",
        "    callbacks,\n",
        "    metrics,\n",
        "    losses,\n",
        "    activations,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPSyZOH6CYGE"
      },
      "outputs": [],
      "source": [
        "def sample_batch(dataset):\n",
        "    batch = dataset.take(1).get_single_element()\n",
        "    if isinstance(batch, tuple):\n",
        "        batch = batch[0]\n",
        "    return batch.numpy()\n",
        "\n",
        "def display(\n",
        "    images, n=10, size=(20, 3), cmap=\"gray_r\", as_type=\"float32\", save_to=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Displays n random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "    if images.max() > 1.0:\n",
        "        images = images / 255.0\n",
        "    elif images.min() < 0.0:\n",
        "        images = (images + 1.0) / 2.0\n",
        "\n",
        "    plt.figure(figsize=size)\n",
        "    for i in range(n):\n",
        "        _ = plt.subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i].astype(as_type), cmap=cmap)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    if save_to:\n",
        "        plt.savefig(save_to)\n",
        "        print(f\"\\nSaved to {save_to}\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1IRe6df7lDS"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "DATASET_REPETITIONS = 5\n",
        "LOAD_MODEL = False\n",
        "\n",
        "NOISE_EMBEDDING_SIZE = 32\n",
        "PLOT_DIFFUSION_STEPS = 20\n",
        "\n",
        "# optimization\n",
        "EMA = 0.999\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g5ZJXzV5DHC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Assuming you have downloaded and extracted the flowers dataset to a local directory\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIas42ZS8-ez"
      },
      "outputs": [],
      "source": [
        "train_data = image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=None, # Adjust batch_size according to your needs\n",
        "    labels=None,\n",
        "    shuffle=True,\n",
        "    interpolation=\"bilinear\",\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqbcOIl35Adz"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "def preprocess(img):\n",
        "    img = tf.cast(img, \"float32\") / 255.0\n",
        "    return img\n",
        "\n",
        "\n",
        "train = train_data.map(lambda x: preprocess(x))\n",
        "train = train.repeat(DATASET_REPETITIONS)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZgUzrB57wNM"
      },
      "outputs": [],
      "source": [
        "# Show some items of clothing from the training set\n",
        "train_sample = sample_batch(train)\n",
        "display(train_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEY30wEm5gt8"
      },
      "outputs": [],
      "source": [
        "def linear_diffusion_schedule(diffusion_times):\n",
        "    min_rate = 0.0001\n",
        "    max_rate = 0.02\n",
        "    betas = min_rate + diffusion_times * (max_rate - min_rate)\n",
        "    alphas = 1 - betas\n",
        "    alpha_bars = tf.math.cumprod(alphas)\n",
        "    signal_rates = tf.sqrt(alpha_bars)\n",
        "    noise_rates = tf.sqrt(1 - alpha_bars)\n",
        "    return noise_rates, signal_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giTDR0uK5mSV"
      },
      "outputs": [],
      "source": [
        "def cosine_diffusion_schedule(diffusion_times):\n",
        "    signal_rates = tf.cos(diffusion_times * math.pi / 2)\n",
        "    noise_rates = tf.sin(diffusion_times * math.pi / 2)\n",
        "    return noise_rates, signal_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CfLkdyF-D-v"
      },
      "outputs": [],
      "source": [
        "def offset_cosine_diffusion_schedule(diffusion_times):\n",
        "    min_signal_rate = 0.02\n",
        "    max_signal_rate = 0.95\n",
        "    start_angle = tf.acos(max_signal_rate)\n",
        "    end_angle = tf.acos(min_signal_rate)\n",
        "\n",
        "    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "\n",
        "    signal_rates = tf.cos(diffusion_angles)\n",
        "    noise_rates = tf.sin(diffusion_angles)\n",
        "\n",
        "    return noise_rates, signal_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mJHK5wq-HmB"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "diffusion_times = tf.convert_to_tensor([x / T for x in range(T)])\n",
        "linear_noise_rates, linear_signal_rates = linear_diffusion_schedule(\n",
        "    diffusion_times\n",
        ")\n",
        "cosine_noise_rates, cosine_signal_rates = cosine_diffusion_schedule(\n",
        "    diffusion_times\n",
        ")\n",
        "(\n",
        "    offset_cosine_noise_rates,\n",
        "    offset_cosine_signal_rates,\n",
        ") = offset_cosine_diffusion_schedule(diffusion_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nW8PaB9-LqT"
      },
      "outputs": [],
      "source": [
        "plt.plot(\n",
        "    diffusion_times, linear_signal_rates**2, linewidth=1.5, label=\"linear\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times, cosine_signal_rates**2, linewidth=1.5, label=\"cosine\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times,\n",
        "    offset_cosine_signal_rates**2,\n",
        "    linewidth=1.5,\n",
        "    label=\"offset_cosine\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"t/T\", fontsize=12)\n",
        "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5cLm-9u-PE9"
      },
      "outputs": [],
      "source": [
        "plt.plot(\n",
        "    diffusion_times, linear_noise_rates**2, linewidth=1.5, label=\"linear\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times, cosine_noise_rates**2, linewidth=1.5, label=\"cosine\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times,\n",
        "    offset_cosine_noise_rates**2,\n",
        "    linewidth=1.5,\n",
        "    label=\"offset_cosine\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"t/T\", fontsize=12)\n",
        "plt.ylabel(r\"$1-\\bar{\\alpha_t}$ (noise)\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8mV7er3-Uaj"
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable() # Register the function for serialization\n",
        "def sinusoidal_embedding(x):\n",
        "    frequencies = tf.exp(\n",
        "        tf.linspace(\n",
        "            tf.math.log(1.0),\n",
        "            tf.math.log(1000.0),\n",
        "            NOISE_EMBEDDING_SIZE // 2,\n",
        "        )\n",
        "    )\n",
        "    angular_speeds = 2.0 * math.pi * frequencies\n",
        "    embeddings = tf.concat(\n",
        "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
        "    )\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag_8h3uC-ZBb"
      },
      "outputs": [],
      "source": [
        "embedding_list = []\n",
        "for y in np.arange(0, 1, 0.01):\n",
        "    embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0])\n",
        "embedding_array = np.array(np.transpose(embedding_list))\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xticks(\n",
        "    np.arange(0, 100, 10), labels=np.round(np.arange(0.0, 1.0, 0.1), 1)\n",
        ")\n",
        "ax.set_ylabel(\"embedding dimension\", fontsize=8)\n",
        "ax.set_xlabel(\"noise variance\", fontsize=8)\n",
        "plt.pcolor(embedding_array, cmap=\"coolwarm\")\n",
        "plt.colorbar(orientation=\"horizontal\", label=\"embedding value\")\n",
        "ax.imshow(embedding_array, interpolation=\"nearest\", origin=\"lower\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrxgkQpw-cWO"
      },
      "outputs": [],
      "source": [
        "def ResidualBlock(width):\n",
        "    def apply(x):\n",
        "        input_width = x.shape[3]\n",
        "        if input_width == width:\n",
        "            residual = x\n",
        "        else:\n",
        "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "        x = layers.BatchNormalization(center=False, scale=False)(x)\n",
        "        x = layers.Conv2D(\n",
        "            width, kernel_size=3, padding=\"same\", activation=activations.swish\n",
        "        )(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "        x = layers.Add()([x, residual])\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def DownBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        for _ in range(block_depth):\n",
        "            x = ResidualBlock(width)(x)\n",
        "            skips.append(x)\n",
        "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def UpBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "        for _ in range(block_depth):\n",
        "            x = layers.Concatenate()([x, skips.pop()])\n",
        "            x = ResidualBlock(width)(x)\n",
        "        return x\n",
        "\n",
        "    return apply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yey2mA0k-lGT"
      },
      "outputs": [],
      "source": [
        "# Build the U-Net\n",
        "\n",
        "noisy_images = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "x = layers.Conv2D(32, kernel_size=1)(noisy_images)\n",
        "\n",
        "noise_variances = layers.Input(shape=(1, 1, 1))\n",
        "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "noise_embedding = layers.UpSampling2D(size=IMAGE_SIZE, interpolation=\"nearest\")(\n",
        "    noise_embedding\n",
        ")\n",
        "\n",
        "x = layers.Concatenate()([x, noise_embedding])\n",
        "\n",
        "skips = []\n",
        "\n",
        "x = DownBlock(32, block_depth=2)([x, skips])\n",
        "x = DownBlock(64, block_depth=2)([x, skips])\n",
        "x = DownBlock(96, block_depth=2)([x, skips])\n",
        "\n",
        "x = ResidualBlock(128)(x)\n",
        "x = ResidualBlock(128)(x)\n",
        "\n",
        "x = UpBlock(96, block_depth=2)([x, skips])\n",
        "x = UpBlock(64, block_depth=2)([x, skips])\n",
        "x = UpBlock(32, block_depth=2)([x, skips])\n",
        "\n",
        "x = layers.Conv2D(3, kernel_size=1, kernel_initializer=\"zeros\")(x)\n",
        "\n",
        "unet = models.Model([noisy_images, noise_variances], x, name=\"unet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnczCApI-m7Z"
      },
      "outputs": [],
      "source": [
        "class DiffusionModel(models.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.normalizer = layers.Normalization()\n",
        "        self.network = unet\n",
        "        self.ema_network = models.clone_model(self.network)\n",
        "        self.diffusion_schedule = offset_cosine_diffusion_schedule\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.noise_loss_tracker = metrics.Mean(name=\"n_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.noise_loss_tracker]\n",
        "\n",
        "    def denormalize(self, images):\n",
        "        images = self.normalizer.mean + images * self.normalizer.variance**0.5\n",
        "        return tf.clip_by_value(images, 0.0, 1.0)\n",
        "\n",
        "    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "        pred_noises = network(\n",
        "            [noisy_images, noise_rates**2], training=training\n",
        "        )\n",
        "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "\n",
        "        return pred_noises, pred_images\n",
        "\n",
        "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
        "        num_images = initial_noise.shape[0]\n",
        "        step_size = 1.0 / diffusion_steps\n",
        "        current_images = initial_noise\n",
        "        for step in range(diffusion_steps):\n",
        "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
        "            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                current_images, noise_rates, signal_rates, training=False\n",
        "            )\n",
        "            next_diffusion_times = diffusion_times - step_size\n",
        "            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n",
        "                next_diffusion_times\n",
        "            )\n",
        "            current_images = (\n",
        "                next_signal_rates * pred_images + next_noise_rates * pred_noises\n",
        "            )\n",
        "        return pred_images\n",
        "\n",
        "    def generate(self, num_images, diffusion_steps, initial_noise=None):\n",
        "        if initial_noise is None:\n",
        "            initial_noise = tf.random.normal(\n",
        "                shape=(num_images, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "            )\n",
        "        generated_images = self.reverse_diffusion(\n",
        "            initial_noise, diffusion_steps\n",
        "        )\n",
        "        generated_images = self.denormalize(generated_images)\n",
        "        return generated_images\n",
        "\n",
        "    def train_step(self, images):\n",
        "        images = self.normalizer(images, training=True)\n",
        "        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "\n",
        "        noisy_images = signal_rates * images + noise_rates * noises\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # train the network to separate noisy images to their components\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                noisy_images, noise_rates, signal_rates, training=True\n",
        "            )\n",
        "\n",
        "            noise_loss = self.loss(noises, pred_noises)  # used for training\n",
        "\n",
        "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(\n",
        "            zip(gradients, self.network.trainable_weights)\n",
        "        )\n",
        "\n",
        "        self.noise_loss_tracker.update_state(noise_loss)\n",
        "\n",
        "        for weight, ema_weight in zip(\n",
        "            self.network.weights, self.ema_network.weights\n",
        "        ):\n",
        "            ema_weight.assign(EMA * ema_weight + (1 - EMA) * weight)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, images):\n",
        "        images = self.normalizer(images, training=False)\n",
        "        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = signal_rates * images + noise_rates * noises\n",
        "        pred_noises, pred_images = self.denoise(\n",
        "            noisy_images, noise_rates, signal_rates, training=False\n",
        "        )\n",
        "        noise_loss = self.loss(noises, pred_noises)\n",
        "        self.noise_loss_tracker.update_state(noise_loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZVL8sNq-vca"
      },
      "outputs": [],
      "source": [
        "ddm = DiffusionModel()\n",
        "ddm.normalizer.adapt(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na5LGZk6-xjC"
      },
      "outputs": [],
      "source": [
        "if LOAD_MODEL:\n",
        "    ddm.built = True\n",
        "    ddm.load_weights(\"/content/checkpoint/checkpoint.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReCSUpm--1Su"
      },
      "outputs": [],
      "source": [
        "ddm.compile(\n",
        "    optimizer=optimizers.AdamW(\n",
        "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    ),\n",
        "    loss=losses.mean_absolute_error,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29Y3P0Qb_r8V"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kCmqnJC_v_z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqZIsWJm_ydH"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIfFA0XF-8je"
      },
      "outputs": [],
      "source": [
        "# run training and plot generated images periodically\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"./checkpoint/checkpoint.weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=\"epoch\",\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_img):\n",
        "        self.num_img = num_img\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        generated_images = self.model.generate(\n",
        "            num_images=self.num_img,\n",
        "            diffusion_steps=PLOT_DIFFUSION_STEPS,\n",
        "        ).numpy()\n",
        "        display(\n",
        "            generated_images,\n",
        "            save_to=\"/content/output/generated_img_%03d.png\" % (epoch),\n",
        "        )\n",
        "\n",
        "\n",
        "image_generator_callback = ImageGenerator(num_img=10)\n",
        "\n",
        "ddm.fit(\n",
        "    train,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        model_checkpoint_callback,\n",
        "        tensorboard_callback,\n",
        "        image_generator_callback,\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3IfbMHP--oB"
      },
      "outputs": [],
      "source": [
        "# Generate some novel images of flowers\n",
        "generated_images = ddm.generate(num_images=10, diffusion_steps=20).numpy()\n",
        "display(generated_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06pzyAr6_C0E"
      },
      "outputs": [],
      "source": [
        "# View improvement over greater number of diffusion steps\n",
        "for diffusion_steps in list(np.arange(1, 6, 1)) + [20] + [100]:\n",
        "    tf.random.set_seed(42)\n",
        "    generated_images = ddm.generate(\n",
        "        num_images=10,\n",
        "        diffusion_steps=diffusion_steps,\n",
        "    ).numpy()\n",
        "    display(generated_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv-V4G_X6TO4"
      },
      "outputs": [],
      "source": [
        "# Interpolation between two points in the latent space\n",
        "\n",
        "\n",
        "def spherical_interpolation(a, b, t):\n",
        "    # Cast t to tf.float32 to match the expected type of a and b\n",
        "    t = tf.cast(t, tf.float32)\n",
        "    # Use tf.math functions to ensure operations remain in TensorFlow\n",
        "    return tf.math.sin(t * math.pi / 2) * a + tf.math.cos(t * math.pi / 2) * b\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    a = tf.random.normal(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), dtype=tf.float32) # Explicitly set dtype to tf.float32\n",
        "    b = tf.random.normal(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), dtype=tf.float32) # Explicitly set dtype to tf.float32\n",
        "    # initial_noise should be a TensorFlow tensor\n",
        "    initial_noise = tf.convert_to_tensor(\n",
        "        [spherical_interpolation(a, b, t) for t in np.arange(0, 1.1, 0.1)]\n",
        "    )\n",
        "    # Cast initial_noise to float32 before passing to generate function\n",
        "    generated_images = ddm.generate(\n",
        "        num_images=2, diffusion_steps=20, initial_noise=tf.cast(initial_noise, tf.float32)\n",
        "    ).numpy()\n",
        "    display(generated_images, n=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTyVyvVuK7fl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
